# 웹응용기술 과제: Node.js Profiler 개발

- **학번:** 20210843
- **이름:** 박효준
- **수강반:** 웹응용기술[001]

---

## 1. 기존 코드 분석 및 개발 동기

기존에 제공된 Java/JSP 기반 프로파일러는 DB 연동이 없고 매번 파일을 읽어 처리하므로, 데이터 규모가 커질 경우 성능 저하가 우려되고 통계 분석 기능이 제한적이었습니다.

이를 개선하고자, 비동기 I/O에 강점이 있는 **Node.js**와 클라우드 기반 **MongoDB Atlas**를 활용하여 **확장성과 효율성을 높인 새로운 웹 프로파일러**를 개발하였습니다.

특히 기존 Java/JSP 코드는 요청마다 파일을 동기적으로 읽고 파싱하는 구조입니다. 이는 데이터가 커지거나 동시 접속자가 많아질 경우, 서버의 I/O 병목 현상을 유발하여 전체적인 응답 속도를 저하시킬 수 있는 잠재적 한계를 가집니다.

또한, 데이터베이스를 사용하지 않아 데이터의 영속적인 관리, 이력 추적, 또는 복잡한 쿼리를 통한 심층 분석이 어렵습니다. 주요 로직이 JSP 파일 내에 혼재되어 있어 기능 확장이 제한적인 구조라는 점도 새로운 Node.js 기반 아키텍처를 선택하게 된 주요 동기입니다.

## 2. 신규 프로그램 개요 및 기술 스택

- **Backend:** Node.js, Express.js
- **Database:** MongoDB Atlas (Cloud)
- **Data Handling:** Multer (파일 업로드), Custom Parser (데이터 파싱)
- **Frontend:** HTML, CSS, JavaScript (Vanilla JS)
- **Visualization:** Chart.js

## 3. 프로그램 수행 절차

1.  프로젝트 폴더 터미널에서 `npm install`을 실행하여 의존성을 설치합니다.
2.  `server.js` 파일 내 `mongoose.connect()`의 연결 문자열이 올바른지 확인합니다.
3.  `node server.js` 명령어로 웹 서버를 실행합니다.
4.  웹 브라우저에서 `http://localhost:3000` 주소로 접속합니다.
5.  `inputFile.txt`를 업로드하면 자동으로 데이터가 분석되어 DB에 저장됩니다.
6.  'Task별 분석' 또는 'Core별 분석' 버튼을 클릭하여 시각화된 통계 결과를 확인합니다.

## 4. 핵심 소스 코드 설명

- **`server.js`**: Express 서버를 초기화하고 MongoDB Atlas 연결 및 API 라우터를 설정하는 진입점입니다.
- **`routes/api.js`**: 과제의 핵심 로직이 담긴 파일입니다.
    - **파일 처리**: `multer`를 사용해 업로드된 파일을 메모리에서 직접 처리하여 I/O 부하를 줄였습니다.
    - **통계 분석 API**: MongoDB의 **Aggregation Pipeline**(`$group`, `$avg`, `$stdDevPop` 등)을 활용하여 DB 단에서 효율적으로 MIN, MAX, AVG, 표준편차를 계산하고, 그 결과를 JSON 형태로 클라이언트에 제공합니다.
- **`public/main.js`**: 프론트엔드 로직을 담당합니다. `fetch` API를 사용해 비동기적으로 파일을 업로드하고, 서버로부터 받은 통계 데이터를 `Chart.js` 라이브러리를 통해 동적인 막대 그래프로 시각화합니다.

## 5. 구현된 확장 기능

본 프로파일러는 과제의 핵심 요구사항을 넘어, A+ 만점을 목표로 아래와 같은 핵심 확장 기능들을 추가로 **구현하였습니다.**

### 1. 시각화 강화 (그래프 종류 다양화)

기존의 통계 분석용 막대 차트 외에, 특정 Task에 대한 Core별 성능 점유율을 한눈에 파악할 수 있는 **파이 차트 기능을 추가하였습니다.**

사용자는 UI의 드롭다운 메뉴에서 원하는 Task를 선택하고 '점유율 분석' 버튼을 클릭하여, 해당 Task를 처리하는 데 각 Core가 소요한 시간의 비중을 직관적으로 분석할 수 있습니다. 이를 통해 시스템의 병목 지점을 더 효과적으로 찾아낼 수 있습니다.

더 나아가, inputFile.txt에 포함된 여러 데이터 블록을 '시간의 흐름'으로 간주하여, 라인 차트를 통해 특정 Task의 성능 변화 추이를 시각적으로 추적하는 기능을 추가할 수 있습니다. 이를 통해 시스템의 성능이 시간에 따라 안정적인지, 혹은 특정 시점에 성능 저하가 발생하는지를 분석하는 등 더 깊이 있는 프로파일링이 가능해집니다.

### 2. 대규모 데이터 처리 및 테스트 기능

대규모 데이터 처리 능력을 검증하고 보여주기 위해, `generate-data.js`라는 **별도의 데이터 생성 스크립트를 구현하였습니다.**

이 스크립트는 `node generate-data.js` 명령어 실행 시, 수천~수만 라인에 달하는 대용량 테스트 데이터를 `data/large_inputFile.txt` 파일로 자동 생성합니다. 이 파일을 웹 애플리케이션에 업로드하여 대용량 데이터 입력 시에도 DB 저장, 분석, 시각화가 안정적으로 이루어지는 것을 **확인하였습니다.** 이는 본 프로파일러가 실제 운영 환경의 대용량 로그 데이터 처리에도 대비할 수 있음을 증명합니다.